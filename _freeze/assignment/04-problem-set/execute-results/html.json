{
  "hash": "99a3480d17f3bbf3c80abe4fa097574a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Problem set 4\"\ndate: \"2025-04-28\"\n---\n\n\n\n\n\n\n## Instructions\n\nPlease use an RMarkdown file to complete this assignment. Make sure you reserve code chunks for code and write out any interpretations or explainations outside of code chunks. Submit the knitted PDF file containing your code and written answers on Canvas. \n\n## Questions\n\n1. Recall the marriage, age, happiness collider example from [Lecture 3-1](https://uobayes.netlify.app/slides/lecture03-1#/32). Run the two models again (`m6a` and `m7`). Compare these two models using PSIS and WAIC. Which model is expected to make better predictions? Is that the model with the correct causal inference?\n\n<details>\n<summary>Click to see the answer</summary>\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(here)\nlibrary(tidyverse)\nlibrary(brms)\nlibrary(tidybayes)\nlibrary(loo)\n\nd <- rethinking::sim_happiness(seed = 1990, N_years = 1000)\n\nd2 <- d[d$age >= 18, ]\nd2$A <- rethinking::standardize(d2$age)\nd2$mid <- as.factor(d2$married + 1)\n\nm6a <- brm(\n  data=d2, \n  family=gaussian,\n  bf( happiness ~ 0 + a + b*A, \n      a ~ 0 + mid,\n      b ~ 0 + mid,\n      nl = TRUE),\n  prior = c( prior(normal(0, .50), nlpar=a),\n             prior(normal(0, .25), nlpar=b),\n             prior(exponential(1), class=sigma)),\n  iter=2000, warmup=1000, seed=9, chains=1,\n  file = here(\"files/models/31.6a\")\n)\n\nm7 <- brm(\n  data=d2, \n  family=gaussian,\n  happiness ~ A,\n  prior = c( prior(normal(0, .50), class=Intercept),\n             prior(normal(0, .25), class=b),\n             prior(exponential(1), class=sigma)),\n  iter=2000, warmup=1000, seed=9, chains=1,\n  file = here(\"files/models/31.7\")\n)\n\nm6a <- add_criterion(m6a, criterion = \"loo\")\nm7 <- add_criterion(m7, criterion = \"loo\")\nm6a <- add_criterion(m6a, criterion = \"waic\")\nm7 <- add_criterion(m7, criterion = \"waic\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nloo_compare(m6a, m7, criterion = \"loo\") %>% print(simplify=F)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    elpd_diff se_diff elpd_loo se_elpd_loo p_loo   se_p_loo looic   se_looic\nm6a     0.0       0.0 -1358.9     18.5         4.5     0.2   2717.8    37.0 \nm7   -191.9      17.4 -1550.8     13.8         2.3     0.1   3101.7    27.7 \n```\n\n\n:::\n\n```{.r .cell-code}\nloo_compare(m6a, m7, criterion = \"waic\") %>% print(simplify=F)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    elpd_diff se_diff elpd_waic se_elpd_waic p_waic  se_p_waic waic    se_waic\nm6a     0.0       0.0 -1358.9      18.5          4.5     0.2    2717.8    37.0\nm7   -191.9      17.4 -1550.8      13.8          2.3     0.1    3101.7    27.7\n```\n\n\n:::\n:::\n\n\n\n\nThe model in which we stratify by age makes better predictions. However, we know this is not the best causal model, as stratifying by marriage constitutes conditioning on a collider. This will yield biased estimates for the relationship between age and happiness. But it will be a better predictor, because we're incorporating more relevant information about happiness into our model. \n\n</details>\n\n2. In 2007, The Wall Street Journal published an editorial (\"Weâ€™re Number One, Alas\") with a graph of corporate tax rates in 29 countries plotted against tax revenue. A badly fit curve was drawn in (see below) to make the argument that the relationship between tax rate and tax revenue increases and then declines, such that higher tax rates can actually produce less tax revenue.\n\n![](../files/img/wsj.gif)\n\nThe data are in the `rethinking` package under the name `Laffer`. Fit two models to the data: one with a straight line and one with an _actual_ curve. Compare these models using PSIS or WAIC. What do you conclude?\n\n<details>\n<summary>Click to see the answer</summary>\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(Laffer, package = \"rethinking\")\nd <- Laffer\nd <- d %>% \n  mutate(across(everything(), rethinking::standardize)) \n\nm_straight = brm(\n  data=d, \n  family = gaussian,\n  tax_revenue ~ tax_rate, \n  prior = c( prior(normal(0,.1), class=Intercept),\n             prior(normal(0,.5), class=b),\n             prior(exponential(1), class=sigma)),\n  iter=3000, warmup=1000, seed=9, chains=4,\n  file = here(\"files/models/hw4.1\")\n)\n\nm_curve = brm(\n  data=d, \n  family = gaussian,\n  tax_revenue ~ tax_rate + I(tax_rate^2), \n  prior = c( prior(normal(0,.1), class=Intercept),\n             prior(normal(0,.5), class=b),\n             prior(exponential(1), class=sigma)),\n  iter=3000, warmup=1000, seed=9, chains=4,\n  file = here(\"files/models/hw4.2\")\n)\n\nm_straight <- add_criterion(m_straight, criterion = \"loo\")\nm_straight <- add_criterion(m_straight, criterion = \"waic\")\n\nm_curve <- add_criterion(m_curve, criterion = \"loo\")\nm_curve <- add_criterion(m_curve, criterion = \"waic\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nloo_compare(m_straight, m_curve, criterion = \"loo\") %>% print(simplify=F)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic\nm_curve      0.0       0.0   -42.5      9.6         5.1   3.8     85.0  19.3   \nm_straight  -0.8       0.9   -43.3      9.7         4.8   3.8     86.6  19.5   \n```\n\n\n:::\n\n```{.r .cell-code}\nloo_compare(m_straight, m_curve, criterion = \"waic\") %>% print(simplify=F)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic \nm_curve      0.0       0.0   -42.0       9.2          4.5    3.4      83.9\nm_straight  -1.0       0.9   -42.9       9.4          4.5    3.4      85.9\n           se_waic\nm_curve     18.4  \nm_straight  18.8  \n```\n\n\n:::\n:::\n\n\n\n\n\n</details>\n\n3. In the problem above, Norway is an outlier. Use PSIS or WAIC to estimate how much influence it has on the models you fit in the previous question.\n\n<details>\n<summary>Click to see the answer</summary>\n\nLet's start by identifying Norway. It has a very high tax revenue, so I'll find the data point with the highest revenue. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n(which_norway = which( d$tax_revenue == max(d$tax_revenue) ))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 12\n```\n\n\n:::\n:::\n\n\n\n\nPoint 12! Let's see how it does on my statistics. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nloo(m_straight)$pointwise[ which_norway, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          elpd_loo      mcse_elpd_loo              p_loo              looic \n       -10.7496180          0.1598491          3.7979043         21.4992360 \ninfluence_pareto_k \n         0.9155318 \n```\n\n\n:::\n\n```{.r .cell-code}\nloo(m_curve)$pointwise[ which_norway, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          elpd_loo      mcse_elpd_loo              p_loo              looic \n       -10.6598434          0.2281193          3.8598310         21.3196868 \ninfluence_pareto_k \n         1.0607814 \n```\n\n\n:::\n\n```{.r .cell-code}\nwaic(m_straight)$pointwise[ which_norway, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n elpd_waic     p_waic       waic \n-10.419245   3.467531  20.838489 \n```\n\n\n:::\n\n```{.r .cell-code}\nwaic(m_curve)$pointwise[ which_norway, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n elpd_waic     p_waic       waic \n-10.182644   3.382631  20.365287 \n```\n\n\n:::\n:::\n\n\n\n\nVery high influence on all of these lines. Let's take just the first one: The influence according to PSIS on the straight curve is 0.92, which is a magnitude larger than almost all other influence metrics. It's between .7 and 1, which puts it in the \"bad\" range (but not \"very bad\"), so take that for what it's worth.\n\n</details>\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}