{
  "hash": "ba1497e57d21e5edd31585178c0e62a0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 1: Introduction to Bayesian Analysis\"\nsubtitle: \"Gardens of forking data\"\nformat: \n  revealjs:\n    css: xaringan-themer2.css\n    nature:\n      highlightStyle: solarized-dark\n      highlightLines: true\n      countIncrementalSlides: false\n      mathjax: \"default\"\n    self-contained: false  # Ensures correct embedding\n    embed-resources: true  # Embeds required assets\n    slide-number: true\nexecute:\n  echo: false  \n---\n\n\n\nWorkspace setup:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(cowplot)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n# Bayes' Theorem\n\nRecall from last lecture, the probability that a specific hypothesis, H, is true given a set of data, D, is defined as:\n\n$$\nP(H|D) = \\frac{P(H)P(D|H)}{P(D)}\n$$\n\nYou can get there via some calculus, but there are other, more intuitive ways of getting to this value. Today, we're going to build up the intuition of this formula.\n\n---\n\n## Globe tossing experiment\n\nSuppose you have a globe representing the planet, and you want to estimate how much of the surface is covered in water. You adopt the following strategy: You toss the globe in the air, and when you catch it, you write down whether the surface under your right thumb is water or land.\n\nWrite a function to simulate tosses of this globe. Make sure your function allows you to vary `N`, the number of tosses, and `p`, the true proportion of water on the globe. \n\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# function to toss a globe covered p by water N times\nsim_globe = function( p=0.7 , N=9 ){\n  sample(\n    x = c(\"W\", \"L\"),  # possible values\n    size = N,         # how many draws\n    prob = c(p, 1-p), # probability of each possibility\n    replace = TRUE    # the same value can be drawn multiple times\n  )\n}\n\nsim_globe()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"L\" \"L\" \"L\" \"L\" \"W\" \"W\" \"W\" \"W\" \"L\"\n```\n\n\n:::\n:::\n\n\n\n---\n\n$$\nP(H|D) = \\frac{P(H)P(D|H)}{P(D)}\n$$\n\n  * $P(H)$ is the prior, and that is set by the researcher. \n  * $P(D)$ is the probability of the data given all possible hypotheses, and is therefore the sum of all the $P(H) \\times P(D|H)$.\n  * So we only need to find $P(D|H)$ or the probability of a sample given a specific, hypothetical value of $H$.\n  \n  What probability distribution would represent the likelihood of a specific sample of water and land given a known propotion of water?\n  \n--\n\nThe **binomial distribution**.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndbinom(x = 6, size = 9, prob = .7)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.2668279\n```\n\n\n:::\n:::\n\n\n\n---\n\n## exercise\n\n\nWrite a function that computes the posterior distribution of $p$, the true proportion of water, based on a given sample and a flat prior. \n\n$$\nP(H|D) = \\frac{P(H)P(D|H)}{P(D)}\n$$\n\n  * $P(H)$ is the prior, and that is set by the researcher. \n  * $P(D)$ is the probability of the data given all possible hypotheses, and is therefore the sum of all the $P(H) \\times P(D|H)$.\n  * So we only need to find $P(D|H)$ or the likelihood of a sample given a specific, hypothetical value of $H$.\n\n\n---\n\n## exercise: solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompute_posterior = function(sample, poss = seq(0,1,length.out=100)){\n  \n  W = sum(sample == \"W\")\n  L = sum(sample == \"L\")\n  \n  likelihood = sapply( poss, function(x) dbinom(x = W, size = W+L, prob = x))\n  \n  post = ( likelihood ) / sum( likelihood)\n  \n  return(post)\n}\n```\n:::\n\n\n\nTesting it out: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(sample = sim_globe())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"W\" \"L\" \"W\" \"L\" \"W\" \"W\" \"L\" \"L\" \"W\"\n```\n\n\n:::\n\n```{.r .cell-code}\ncompute_posterior(sample)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  [1] 0.000000e+00 1.285059e-09 3.946894e-08 2.875476e-07 1.162018e-06\n  [6] 3.399226e-06 8.104135e-06 1.677491e-05 3.130647e-05 5.397606e-05\n [11] 8.741352e-05 1.345590e-04 1.986103e-04 2.829627e-04 3.911420e-04\n [16] 5.267348e-04 6.933155e-04 8.943729e-04 1.133238e-03 1.413014e-03\n [21] 1.736509e-03 2.106170e-03 2.524032e-03 2.991659e-03 3.510103e-03\n [26] 4.079862e-03 4.700854e-03 5.372388e-03 6.093154e-03 6.861211e-03\n [31] 7.673990e-03 8.528305e-03 9.420364e-03 1.034580e-02 1.129969e-02\n [36] 1.227662e-02 1.327068e-02 1.427559e-02 1.528466e-02 1.629096e-02\n [41] 1.728728e-02 1.826627e-02 1.922049e-02 2.014248e-02 2.102484e-02\n [46] 2.186030e-02 2.264181e-02 2.336260e-02 2.401627e-02 2.459682e-02\n [51] 2.509880e-02 2.551728e-02 2.584799e-02 2.608731e-02 2.623237e-02\n [56] 2.628105e-02 2.623207e-02 2.608495e-02 2.584009e-02 2.549873e-02\n [61] 2.506301e-02 2.453591e-02 2.392125e-02 2.322370e-02 2.244867e-02\n [66] 2.160235e-02 2.069160e-02 1.972389e-02 1.870725e-02 1.765018e-02\n [71] 1.656154e-02 1.545050e-02 1.432637e-02 1.319855e-02 1.207639e-02\n [76] 1.096907e-02 9.885483e-03 8.834113e-03 7.822918e-03 6.859209e-03\n [81] 5.949534e-03 5.099572e-03 4.314034e-03 3.596574e-03 2.949715e-03\n [86] 2.374791e-03 1.871907e-03 1.439925e-03 1.076472e-03 7.779804e-04\n [91] 5.397606e-04 3.561111e-04 2.204702e-04 1.256141e-04 6.390545e-05\n [96] 2.759794e-05 9.201524e-06 1.914244e-06 1.259357e-07 0.000000e+00\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(seq(0,1,length.out=100), compute_posterior(sample), type = \"l\")\n```\n\n::: {.cell-output-display}\n![](lecture01-2_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\n\n---\n\n## exercise\n\n\nCompute and plot the grid approximate posterior distribution for each of the following sets of observations. In each case, assume a uniform prior for $p$:\n\n  * W W W\n  * W W W L\n  * L W W L W W W\n  \n---\n\n## exercise: solution p1\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample = c(\"W\", \"W\", \"W\")\nplot(seq(0,1,length.out=100), compute_posterior(sample), type = \"l\")\n```\n\n::: {.cell-output-display}\n![](lecture01-2_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n\n---\n\n## exercise: solution p2\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample = c(\"W\", \"W\", \"W\", \"L\")\nplot(seq(0,1,length.out=100), compute_posterior(sample), type = \"l\")\n```\n\n::: {.cell-output-display}\n![](lecture01-2_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n---\n\n## exercise: solution p3\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample = c(\"L\", \"W\", \"W\", \"L\", \"W\", \"W\", \"W\")\nplot(seq(0,1,length.out=100), compute_posterior(sample), type = \"l\")\n```\n\n::: {.cell-output-display}\n![](lecture01-2_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n---\n\n## exercise\n\nNow assume a prior for $p$ that is equal to zero when $p < 0.5$ and is a positive constant when $p â‰¥ 0.5$. Again compute and plot the grid approximate posterior distribution for each of the sets of observations in the prior problem.\n\n---\n\n## exercise: solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompute_posterior = function(sample, poss = seq(0,1,length.out=100)){\n  \n  W = sum(sample == \"W\")\n  L = sum(sample == \"L\")\n  \n  prior = ifelse(poss < .5, 0, 1)\n  \n  likelihood = sapply( poss, function(x) dbinom(x = W, size = W+L, prob = x))\n  \n  post = ( prior*likelihood ) / sum( prior*likelihood)\n  \n  return(post)\n}\n```\n:::\n\n\n\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample = c(\"W\", \"W\", \"W\")\nplot(seq(0,1,length.out=100), compute_posterior(sample), type = \"l\")\n```\n\n::: {.cell-output-display}\n![](lecture01-2_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample = c(\"W\", \"W\", \"W\", \"L\")\nplot(seq(0,1,length.out=100), compute_posterior(sample), type = \"l\")\n```\n\n::: {.cell-output-display}\n![](lecture01-2_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample = c(\"L\", \"W\", \"W\", \"L\", \"W\", \"W\", \"W\")\nplot(seq(0,1,length.out=100), compute_posterior(sample), type = \"l\")\n```\n\n::: {.cell-output-display}\n![](lecture01-2_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n\n---\n\n## exercise\n\nSuppose the globe tossing data had turned out to be 8 water in 15 tosses. Construct the posterior distribution, using grid approximation. Use the same flat prior as before.\n\nDraw 10,000 samples from the grid approximation from above. Then use the samples to calculate the 90% HPDI for $p$.\n\n---\n\n## exercise: solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_grid <- seq( from=0 , to=1 , length.out=1000 )\nprior <- rep( 1 , 1000 )\nlikelihood <- dbinom( 8 , size=15 , prob=p_grid )\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\nset.seed(100)\nsamples <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )\nrethinking::HPDI(samples, prob = .90)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     |0.9      0.9| \n0.3343343 0.7217217 \n```\n\n\n:::\n:::\n\n\n\n---\n\n## exercise\n\n\nConstruct a posterior predictive check for this model and data. This means simulate the distribution of samples, averaging over the posterior uncertainty in $p$. What is the probability of observing 8 water in 15 tosses?\n\n---\n\n## exercise: solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndummy_w <- rbinom(1e4, 15, prob = samples)\ntable(dummy_w)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndummy_w\n   0    1    2    3    4    5    6    7    8    9   10   11   12   13   14   15 \n   6   32  129  272  526  851 1192 1393 1425 1405 1110  815  449  285   86   24 \n```\n\n\n:::\n\n```{.r .cell-code}\nsum(dummy_w == 8)/1e4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1425\n```\n\n\n:::\n:::\n\n\n\n---\n\n## exercise\n\n\nNow use a prior that is zero below $p <.5$ and a positive constant otherwise. Repeat each problem above and compare the inferences. What difference does the better prior make? \n\n  * Calculate the 90% HDPI. \n  * What is the probability of observing 8 water in 15 tosses?\n  \n---\n\n## exercise: solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_grid <- seq( from=0 , to=1 , length.out=1000 )\nprior <- ifelse(p_grid < .5, 0, 1)\nlikelihood <- dbinom( 8 , size=15 , prob=p_grid )\nposterior <- likelihood * prior\nposterior <- posterior / sum(posterior)\nset.seed(100)\nsamples <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )\nrethinking::HPDI(samples, prob = .90)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     |0.9      0.9| \n0.5005005 0.7097097 \n```\n\n\n:::\n:::\n\n\n\n---\n\n## exercise: solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndummy_w <- rbinom(1e4, 15, prob = samples)\ntable(dummy_w)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndummy_w\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15 \n   2    7   35  132  347  684 1081 1630 1776 1667 1273  769  388  184   25 \n```\n\n\n:::\n\n```{.r .cell-code}\nsum(dummy_w == 8)/1e4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.163\n```\n\n\n:::\n:::",
    "supporting": [
      "lecture01-2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}