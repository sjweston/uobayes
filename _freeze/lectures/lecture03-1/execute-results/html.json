{
  "hash": "62a8073f4168502fc6a9a76f01be66b5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 3: Causes, Confounds, and Colliders\"\nsubtitle: \"Elemental confounds\"\nformat: \n  revealjs:\n    css: xaringan-themer2.css\n    nature:\n      highlightStyle: solarized-dark\n      highlightLines: true\n      countIncrementalSlides: false\n      mathjax: \"default\"\n    self-contained: false  # Ensures correct embedding\n    embed-resources: true  # Embeds required assets\n    slide-number: true\n---\n\n\n\nWorkspace setup:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(cowplot)\nlibrary(rethinking)\nlibrary(patchwork)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\nLast week, we started to build out multiple regression models, those that include both categorical and continuous variables as \"main effects\" or predictors in a model. These are simple multiple regression models, and they can be extremely useful for things like revealing **spurious correlations** -- zero-order correlations that suggest association even when the two variables are not causally related -- and important correlations that are masked by other variables.\n\nHowever, you cannot interpret the coefficients in any multiple regression model without identifying the underlying causal model. This week, we'll use **Directed Acyclic Graphs (DAGs)** to develop and visualize our causal models. These DAGs will then help us determine which variables, if any, to control for when trying to estimate causal pathways. Along the way, we'll discuss some common mistakes when it comes to controls and their disasterious consequences.\n\nThis will also be a good opportunity to practice the mathematical models and code we've discussed before, but there will be little new code this week.\n\n------------------------------------------------------------------------\n\n![](images/Lecture_05-waffles.jpg)\n\n------------------------------------------------------------------------\n\n## Forks\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dagitty)\ndag3.1 <- dagitty( \"dag{ Z -> X; Z -> Y }\" )\ncoordinates(dag3.1) <- list( x=c(X=-1,Z=0,Y=1) , y=c(X=0,Z=-1,Y=0) )\ndrawdag( dag3.1, cex = 3, lwd = 3 )\n```\n\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/unnamed-chunk-3-1.png){width=768}\n:::\n:::\n\n\n\nTrue confounds.\n\nNot stratifying on (controlling for) Z will yield a spurious relationship between X and Y. That is, a correlation of X and Y (or regression) will be non-zero, even though there is no causal relationship from one to another.\n\n------------------------------------------------------------------------\n\n## Marriage example\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(WaffleDivorce, package = \"rethinking\")\nd <- WaffleDivorce\n```\n:::\n\n\n\n### exercise\n\nCreate two plots, one showing the relationship between marriage rate and divorce rate and another showing the relationship between median age at marriage and divorce rate.\n\n------------------------------------------------------------------------\n\n### solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\np1 <- d %>% ggplot(aes(x = Marriage, y = Divorce)) +\n  geom_point(color = \"#1c5253\") +\n  geom_smooth(method = \"lm\", color = \"black\") +\n  labs(x = \"marriage rate\", y = \"divorce rate\")\n\np2 <- d %>% ggplot(aes(x = MedianAgeMarriage, y = Divorce)) +\n  geom_point(color = \"#1c5253\") +\n  geom_smooth(method = \"lm\", color = \"black\") +\n  labs(x = \"median age at marriage\", y = \"divorce rate\")\n\n(p1 | p2)\n```\n\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### exercise\n\nModel the relationship between Divorce Rate (D) and Marriage Rate (M). (Standardize both first.) Be sure to do the following:\n\n-   Write a mathematical model expressing this relationship including priors.\n\n-   Sample from your priors to evaluate them.\n\n-   Calculate your posterior predictions for the relationship between D and M.\n\n:::{.fragment}\n\n### solution\n\n\\begin{align*}\nD_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta_MM_i \\\\\n\\alpha &\\sim \\text{Normal}(0, 0.2) \\\\\n\\beta_M &\\sim \\text{Normal}(0, 0.5) \\\\\n\\sigma &\\sim \\text{Exponential}(1) \\\\\n\\end{align*}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd$D <- standardize(d$Divorce)\nd$M <- standardize(d$Marriage)\n```\n:::\n\n\n\n:::\n\n------------------------------------------------------------------------\n\n### solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflist <- alist(\n  D ~ dnorm( mu, sigma),\n  mu <- a + bM * M,\n  a ~ dnorm(0, 0.2),\n  bM ~ dnorm(0, 0.5),\n  sigma ~ dexp(1)\n)\n\nm3.1 <- quap(flist = flist, data = d)\n```\n:::\n\n\n\n------------------------------------------------------------------------\n\n### solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npriors <- extract.prior(m3.1)\nmu <- link( m3.1 , post=priors , data=list( M=c(-2,3) ) )\nplot( D ~ M , data=d, xlab = \"marriage rate\", ylab = \"divorce rate\" )\nfor ( i in 1:50 ) lines( c(-2,3) , mu[i,] , col=col.alpha(\"#1c5253\",0.4) )\n```\n\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprecis(m3.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              mean         sd       5.5%     94.5%\na     2.054143e-05 0.10824937 -0.1729829 0.1730239\nbM    3.500351e-01 0.12593212  0.1487713 0.5512990\nsigma 9.103005e-01 0.08987105  0.7666692 1.0539318\n```\n\n\n:::\n:::\n\n\n\nBonus: a plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n# compute percentile interval of mean\nM_seq <- seq( from=-3 , to=3.2 , length.out=30 )\nmu <- link( m3.1 , data=list(M=M_seq) )\nmu.mean <- apply( mu , 2, mean )\nmu.PI <- apply( mu , 2 , PI )\n\n\n# plot it all\nplot( D ~ M , data=d , col= \"#1c5253\", xlab = \"marriage rate\", ylab = \"divorce rate\" )\nlines( M_seq , mu.mean , lwd=2 )\nshade( mu.PI , M_seq )\n```\n\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\nNow we're going to incorporate state age (median age at marriage) into our model. This is the DAG proposed by RM. What does this DAG represent?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndag3.2 <- dagitty( \"dag{ A -> D; A -> M; M -> D }\" )\ncoordinates(dag3.2) <- list( x=c(A=0,D=1,M=2) , y=c(A=0,D=1,M=0) )\ndrawdag( dag3.2, cex = 3, lwd = 3 )\n```\n\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### forks\n\nDAG models help us to see **conditional independencies**.\n\n-   statements of which variables should be associated with each other (or not) in the data.\n-   statements of which variables become disassociated when we condition on some other set of variables.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimpliedConditionalIndependencies( dag3.2 ) #none\n```\n:::\n\n\n\n::: notes\nimplication is that if we find any of these three variables are uncorrelated, our DAG is wrong.\n:::\n\n------------------------------------------------------------------------\n\nHow does this change with a new DAG?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndag3.3 <- dagitty( \"dag{ A -> D; A -> M }\" )\ncoordinates(dag3.3) <- list( x=c(A=0,D=1,M=2) , y=c(A=0,D=1,M=0) )\ndrawdag( dag3.3, cex = 3, lwd = 3 )\n```\n\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n\n```{.r .cell-code}\nimpliedConditionalIndependencies( dag3.3 ) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nD _||_ M | A\n```\n\n\n:::\n:::\n\n\n\n::: notes\nimplication that D and M will be independent after stratifying on A. We can test this.\n:::\n\n------------------------------------------------------------------------\n\n\\begin{align*}\nD_i &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= \\alpha + \\beta_AA_i + \\beta_MM_i\\\\\n\\alpha &\\sim \\text{Normal}(0, 0.2) \\\\\n\\beta_A &\\sim \\text{Normal}(0, 0.5) \\\\\n\\beta_M &\\sim \\text{Normal}(0, 0.5) \\\\\n\\sigma &\\sim \\text{Exponential}(1) \\\\\n\\end{align*}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd$A <- standardize(d$MedianAgeMarriage)\n```\n:::\n\n\n\n------------------------------------------------------------------------\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflist <- alist(\n  D ~ dnorm( mu, sigma),\n  mu <- a + bA * A + bM * M,\n  a ~ dnorm(0, 0.2),\n  bA ~ dnorm(0, 0.5),\n  bM ~ dnorm(0, 0.5),\n  sigma ~ dexp(1)\n)\n\nm3.2 <- quap(flist = flist, data = d)\nprecis(m3.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               mean         sd       5.5%      94.5%\na      3.836799e-06 0.09707548 -0.1551415  0.1551492\nbA    -6.133942e-01 0.15098419 -0.8546961 -0.3720923\nbM    -6.524857e-02 0.15077339 -0.3062136  0.1757164\nsigma  7.851122e-01 0.07784206  0.6607056  0.9095188\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot( coeftab(m3.1,m3.2), par=c(\"bA\",\"bM\") )\n```\n\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/unnamed-chunk-16-1.png){width=960}\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\nIf we want to simulate the effect of manipulating marriage, we use \"do calculus.\" We do this by effectively \"deleting\" the arrows going into our manipulation variable (M).\n\n::::: columns\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/do-M-1.png){width=960}\n:::\n:::\n\n\n:::\n:::::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npost <- extract.samples(m3.2) # get 10k samples of all parameters\nn <- 1e4\nAs <- sample(d$A, size=n, replace=T) #sample from original data\n\n# simulate D for M=0\nDM0 <- with( post ,\n             rnorm(n, a + bM*0 + bA*As, sigma))\n# simulate D for M=1 -- SAME A values\nDM1 <- with( post ,\n             rnorm(n, a + bM*1 + bA*As, sigma))\n\n#contrast\nM10_con <- DM1 - DM0\ndens(M10_con, lwd=4, col = \"#1c5253\", xlab=\"effect of 1SD increase in M\")\n```\n:::\n\n\n\n\n\n\n------------------------------------------------------------------------\n\n### Pipes\n\nA pipe in a DAG model represents a situation where a variable acts as a mediator between two other variables. In this context, the effect of one variable on another is transmitted through the mediator.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndag_pipe <- dagitty(\"dag{ X -> M -> Y }\")\ncoordinates(dag_pipe) <- list(x=c(X=0, M=1, Y=2), y=c(X=0, M=1, Y=0))\ndrawdag(dag_pipe, cex = 3, lwd = 3)\n```\n\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n\n\nOne place that pipes show up is in **post-treatment bias.**\n\n------------------------------------------------------------------------\n\nSuppose you are studying plants in a greenhouse, and you want to know how effective a particular fungal treatment is. Fungus on plants tends to reduce their growth. You plant a bunch of plants, measure them, then apply one of two different treatments. After some time, you measure the plants again, and you measure the amount of fungus on the plants.\n\nSimulate some fake plant data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(71)\n# number of plants\nN <- 100\n# simulate initial heights\nh0 <- rnorm(N,10,2)\n# assign treatments and simulate fungus and growth\ntreatment <- rep( 0:1 , each=N/2 )\nfungus <- rbinom( N , size=1 , prob=0.5 - treatment*0.4 )\nh1 <- h0 + rnorm(N, 5 - 3*fungus)\n# compose a clean data frame\nd <- data.frame( h0=h0 , h1=h1 , treatment=treatment , fungus=fungus )\nprecis(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              mean        sd      5.5%    94.5%    histogram\nh0         9.95978 2.1011623  6.570328 13.07874 ▁▂▂▂▇▃▂▃▁▁▁▁\nh1        14.39920 2.6880870 10.618002 17.93369     ▁▁▃▇▇▇▁▁\ntreatment  0.50000 0.5025189  0.000000  1.00000   ▇▁▁▁▁▁▁▁▁▇\nfungus     0.23000 0.4229526  0.000000  1.00000   ▇▁▁▁▁▁▁▁▁▂\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n## exercise\n\nDraw the dag that describes the relationships between these 4 variables.\n\nWhat are the implied conditional independences?\n\n------------------------------------------------------------------------\n\n### solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplant_dag <- dagitty( \"dag {\n  H_0 -> H_1\n  F -> H_1\n  T -> F}\" )\n\ncoordinates( plant_dag ) <- list( x=c(H_0=1.0,T=0,F=0.5,H_1=1),\n                                  y=c(H_0=-.5,T=0,F=0.5,H_1=0) )\n\ndrawdag( plant_dag, cex = 3, lwd = 3 )\n```\n\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n\n```{.r .cell-code}\nimpliedConditionalIndependencies(plant_dag)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nF _||_ H_0\nH_0 _||_ T\nH_1 _||_ T | F\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\nLet's start by just modeling growth using our two height variables.\n\n\\begin{align*}\nh_{1,i} &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= h_{0,i} \\times p \\\\\np &\\sim \\text{Log Normal}(0, .25) \\\\\n\\sigma &\\sim \\text{Exponential}(1)\n\\end{align*}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflist <- alist(\n  h1 ~ dnorm(mu, sigma),\n  mu <- h0*p,\n  p ~ dlnorm(0, .25),\n  sigma ~ dexp(1)\n)\n\nm3.3 <- quap(flist, d)\nprecis(m3.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          mean         sd     5.5%    94.5%\np     1.426628 0.01759792 1.398503 1.454753\nsigma 1.792063 0.12496047 1.592352 1.991774\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\nNow add treatment to this model.\n\n\\begin{align*}\nh_{1,i} &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= h_{0,i} \\times p \\\\\np &= \\alpha + \\beta_TT_i \\\\\n\\alpha &\\sim \\text{Log Normal}(0, .25) \\\\\n\\beta_T &\\sim \\text{Normal}(0, .5) \\\\\n\\sigma &\\sim \\text{Exponential}(1)\n\\end{align*}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflist <- alist(\n  h1 ~ dnorm(mu, sigma),\n  mu <- h0*p,\n  p <- a + bT * treatment,\n  a ~ dlnorm(0, .25),\n  bT ~ dnorm(0, .5),\n  sigma ~ dexp(1)\n)\n\nm3.4 <- quap(flist, d)\nprecis(m3.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            mean         sd       5.5%     94.5%\na     1.38168552 0.02519767 1.34141478 1.4219563\nbT    0.08366426 0.03431331 0.02882496 0.1385036\nsigma 1.74629961 0.12190865 1.55146604 1.9411332\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### exercise\n\nNow add in both treatment and fungus to this model.\n\n------------------------------------------------------------------------\n\n### solution\n\n\\begin{align*}\nh_{1,i} &\\sim \\text{Normal}(\\mu_i, \\sigma) \\\\\n\\mu_i &= h_{0,i} \\times p \\\\\np &= \\alpha + \\beta_TT_i + \\beta_FF_i \\\\\n\\alpha &\\sim \\text{Log Normal}(0, .25) \\\\\n\\beta_T &\\sim \\text{Normal}(0, .5) \\\\\n\\beta_F &\\sim \\text{Normal}(0, .5) \\\\\n\\sigma &\\sim \\text{Exponential}(1)\n\\end{align*}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflist <- alist(\n  h1 ~ dnorm(mu, sigma),\n  mu <- h0*p,\n  p <- a + bT * treatment + bF * fungus,\n  a ~ dlnorm(0, .25),\n  bT ~ dnorm(0, .5),\n  bF ~ dnorm(0, .5),\n  sigma ~ dexp(1)\n)\n\nm3.4 <- quap(flist, d)\nprecis(m3.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              mean         sd        5.5%       94.5%\na      1.482826896 0.02452192  1.44363614  1.52201765\nbT     0.001060225 0.02987668 -0.04668849  0.04880894\nbF    -0.267912187 0.03654981 -0.32632584 -0.20949853\nsigma  1.408656542 0.09859148  1.25108831  1.56622477\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n## colliders\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndag3.4 <- dagitty( \"dag{ X -> Z; Y -> Z }\" )\ncoordinates(dag3.4) <- list( x=c(X=-1,Z=0,Y=1) , y=c(X=0,Z=1,Y=0) )\ndrawdag( dag3.4, cex = 3, lwd = 3 )\n```\n\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/unnamed-chunk-25-1.png){width=768}\n:::\n:::\n\n\n\nStratifying on Z opens up the association between X and Y. We do *not* want to stratify on Z.\n\n------------------------------------------------------------------------\n\n### collider of false sorrow\n\nWe'll use the `rethinking` package to simulate data:\n\n-   Each year, 20 people are born with uniformly distributed happiness values.\n-   Each year, each person ages one year. Happiness does not change.\n-   At age 18, individuals can become married. The odds of marriage each year are proportional to an individual’s happiness.\n-   Once married, an individual remains married.\n-   After age 65, individuals leave the sample. (They move to Spain.)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- sim_happiness(seed = 1990, N_years = 1000)\nprecis(d)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  mean         sd      5.5%     94.5%     histogram\nage       3.300000e+01 18.7688832  4.000000 62.000000 ▇▇▇▇▇▇▇▇▇▇▇▇▇\nmarried   2.946154e-01  0.4560451  0.000000  1.000000    ▇▁▁▁▁▁▁▁▁▃\nhappiness 6.832142e-19  1.2144211 -1.789474  1.789474      ▇▅▇▅▅▇▅▇\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\nd %>% \n  mutate(married = factor(married, labels = c(\"unmarried\", \"married\"))) %>% \n  ggplot(aes( x = age, y = happiness)) +\n  geom_point( aes( color = married), size = 3) +\n  scale_color_manual(\"\",\n                       values = c(\"unmarried\" = \"lightgrey\",\n                                  \"married\" = \"#1c5253\")) +\n  theme(legend.position = \"top\")\n```\n\n::: {.cell-output-display}\n![](lecture03-1_files/figure-revealjs/unnamed-chunk-27-1.png){width=864}\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### exercise\n\nFilter out people who are younger than 18. Then fit two models:\n\n(1) a model in which happiness is influenced by both marriage and age.\n(2) a model in which happiness is influenced only by age.\n\n(You may want to center or standardize age in some way.)\n\n------------------------------------------------------------------------\n\n### solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd2 <- d[d$age >= 18, ]\nd2$A <- standardize(d2$age)\nd2$mid <- d2$married + 1\nprecis(d2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                   mean         sd      5.5%     94.5%  histogram\nage        4.150000e+01 13.8606201 20.000000 63.000000 ▃▇▇▇▇▇▇▇▇▇\nmarried    3.989583e-01  0.4899394  0.000000  1.000000 ▇▁▁▁▁▁▁▁▁▅\nhappiness  9.251859e-19  1.2145867 -1.789474  1.789474   ▇▅▇▅▅▇▅▇\nA         -6.476301e-18  1.0000000 -1.551157  1.551157   ▃▇▇▇▇▇▇▃\nmid        1.398958e+00  0.4899394  1.000000  2.000000 ▇▁▁▁▁▁▁▁▁▅\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflist <- alist(\n  happiness ~ dnorm( mu, sigma ),\n  mu <- a[mid] + bA*A,\n  a[mid] ~ dnorm( 0, 0.5),\n  bA ~ dnorm( 0, 0.25),\n  sigma ~ dexp(1)\n)\n\nm3.5 <- quap(flist, d2)\nprecis(m3.5, depth=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            mean         sd       5.5%      94.5%\na[1]  -0.5905624 0.04197727 -0.6576502 -0.5234746\na[2]   0.8866633 0.05191218  0.8036976  0.9696290\nbA    -0.2136768 0.03329633 -0.2668908 -0.1604629\nsigma  0.9928218 0.02264183  0.9566358  1.0290078\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### solution\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflist <- alist(\n  happiness ~ dnorm( mu, sigma ),\n  mu <- a + bA*A,\n  a ~ dnorm( 0, 0.5),\n  bA ~ dnorm( 0, 0.25),\n  sigma ~ dexp(1)\n)\n\nm3.6 <- quap(flist, d2)\nprecis(m3.6, depth=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               mean         sd        5.5%      94.5%\na      7.215763e-07 0.03903552 -0.06238558 0.06238703\nbA    -1.864706e-07 0.03870314 -0.06185527 0.06185490\nsigma  1.213174e+00 0.02766004  1.16896820 1.25738038\n```\n\n\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n## testing DAG assumptions\n\n-   Causal DAGs make strong assumptions about unobserved confounders, but analyzing them can still provide valuable insights about where our models might be wrong through testing implied relationships.\n\n-   Conditional independencies are key testable implications of a DAG, representing pairs of variables that should show no association after controlling for specific sets of other variables.\n\n-   We can identify conditional independencies using the same path analysis techniques used for finding backdoor paths - examining all paths between two variables and determining if there exists a conditioning set that blocks all paths.\n\n-   While manually deriving conditional independencies in large graphs is complex due to the many variable pairs and paths to consider, computational tools can efficiently perform these calculations.\n",
    "supporting": [
      "lecture03-1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}