{
  "hash": "b92733793f7756fe4a31c0e98ed6c6c3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Week 3: Causes, Confounds, and Colliders\"\nsubtitle: \"Good and bad controls\"\nformat: \n  revealjs:\n    css: xaringan-themer2.css\n    nature:\n      highlightStyle: solarized-dark\n      highlightLines: true\n      countIncrementalSlides: false\n      mathjax: \"default\"\n    self-contained: false  # Ensures correct embedding\n    embed-resources: true  # Embeds required assets\n    slide-number: true\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n------------------------------------------------------------------------\n\n![](images/Lecture_05-waffles.jpg)\n\n------------------------------------------------------------------------\n\n### finding backdoor paths\n\n1.  Start at treatment (X)\n\n2.  Look for any arrows coming INTO X\n\n3.  Follow all possible paths to outcome (Y)\n\n4.  A valid adjustment set blocks all backdoor paths\n\n5.  But be careful not to control for colliders!\n\n### exercise\n\nGo to [dagitty.net](https://dagitty.net/) and create this DAG:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lecture03-2_files/figure-revealjs/unnamed-chunk-3-1.png){width=768}\n:::\n:::\n\n\n\n------------------------------------------------------------------------\n\n### exercise\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](lecture03-2_files/figure-revealjs/unnamed-chunk-4-1.png){width=384}\n:::\n:::\n\n\n\n1.  List all paths between Exercise and Health\n2.  Identify which paths are backdoor paths\n3.  Find all valid adjustment sets if we want to estimate the effect of Exercise on Health\n4.  BONUS: What happens if we control for Motivation? Why?\n\n::: notes\nPaths:\n\nExercise → Health (direct/front-door) Exercise ← Motivation → Health (backdoor) Exercise ← Motivation → Diet ← Age → Health (backdoor)\n\nValid adjustment sets:\n\n-   Motivation\n-   Motivation, Age\n:::\n\n------------------------------------------------------------------------\n\n### exercise: simulate simple confounding {.scrollable}\n\nCopy this code from the slides or the class book (Simulation 1: Simple Confounding).\n\n1.  Run the base simulation and observe results\n\n2.  Modify the simulation parameters:\n\n-   Change the strength of the confounding (modify the 0.5, 0.8, and 0.6 coefficients)\n-   Change the sample size (N)\n-   Add a true causal effect (modify Y calculation to include X)\n\n3.  Answer these questions:\n\n-   What happens to the bias in the naive estimate as you increase the strength of confounding?\n-   How does sample size affect the precision of your estimates?\n-   When does controlling for Z fail to recover the true causal effect?\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\n#number of sims\nN = 1000\n# Generate data\nU <- rnorm(N)  # Unobserved confounder\nX <- rnorm(N, mean = 0.5 * U)  # Treatment affected by U\nY <- rnorm(N, mean = 0.8 * U)  # Outcome affected by U\nZ <- rnorm(N, mean = 0.6 * U)  # Observed variable that captures U\n\nd <- data.frame(X, Y, Z)\n\n# Fit models\nflist1 <- alist(\n  Y ~ dnorm(mu, sigma),\n  mu <- a + bX*X,\n  a ~ dnorm(0, .5),\n  bX ~ dnorm(0, .25),\n  sigma ~ dexp(1)\n)\n\nm32.1 <- quap(flist1, d)\nprecis(m32.1)\n\n# Fit models\nflist2 <- alist(\n  Y ~ dnorm(mu, sigma),\n  mu <- a + bX*X +bZ*Z,\n  a ~ dnorm(0, .5),\n  bX ~ dnorm(0, .25),\n  bZ ~ dnorm(0, .25),\n  sigma ~ dexp(1)\n)\n\nm32.2 <- quap(flist2, d)\nprecis(m32.2)\n\npost.1 <- extract.samples(m32.1)\npost.2 <- extract.samples(m32.2)\n\nresults_df = data.frame(naive = post.1$bX,\n                        adjusted = post.2$bX)\nresults_df %>% \n  pivot_longer(everything()) %>% \n  ggplot(aes(x = value, fill = name)) +\n  geom_density(alpha = .5) +\n  geom_vline(aes(xintercept = 0), linetype = \"dashed\")\n```\n:::\n\n\n\n------------------------------------------------------------------------\n\n### bad controls\n\n\"Bad controls\" can create bias in three main ways:\n\n-   Collider bias (as we saw in the previous exercise)\n-   Precision parasites (reduce precision without addressing confounding)\n-   Bias amplification (making existing bias worse)\n\nWarning signs of bad controls:\n\n-   Post-treatment variables\n-   Variables affected by both treatment and outcome\n-   Variables that don't address actual confounding paths\n\n------------------------------------------------------------------------\n\n### exercise\n\nUse this code to simulate new variables:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn = 100\n# Z affects X but is not a confounder\nZ <- rnorm(n)\nX <- rnorm(n, mean = Z)\nY <- rnorm(n, mean = X)  # True effect of X on Y is 1\n```\n:::\n\n\n\nUsing different sample sizes (n = 50, 100, 1000), test two models exploring the relationship between X (exposure) and Y (outcome). For each sample size, compare:\n\n-   Standard errors without controlling for Z\n-   Standard errors when controlling for Z\n\nHow does sample size affect the impact of the precision parasite (Z)? Under what conditions is the precision loss most severe?\n\n------------------------------------------------------------------------\n\n### exercise\n\nUse this code to simulate new variables:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn = 100\nconf_strength = 1\n# U is unmeasured confounder\nU <- rnorm(n)\nZ <- rnorm(n)\nX <- rnorm(n, mean = Z + conf_strength * U)\nY <- rnorm(n, mean = conf_strength * U)  # No true effect of X\n```\n:::\n\n\n\nUsing different confounder strengths (0.5, 1, 2), test two models exploring the relationship between X (exposure) and Y (outcome). For each sample size, compare:\n\n-   Standard errors without controlling for Z\n-   Standard errors when controlling for Z\n\nQuestions: \\* What happens to the bias when you control for Z? \\* How does the strength of the confounding affect the amount of bias amplification? \\* Can you explain why this happens using the DAG?\n\n------------------------------------------------------------------------\n\n### exercise\n\nUse the simulation code provided in the last two exercises to create a new scenario with both a precision parasite variable (Z1) and a bias amplification variable (Z2).\n\nQuestions:\n\n-   What happens to our estimates when we control for both variables?\n\n-   Is it better to:\n\n    -   Control for neither\n    -   Control for just one (which one?)\n    -   Control for both\n\n-   How can we use DAGs to decide which controls to include?\n\n------------------------------------------------------------------------\n\n### table 2 fallacy\n\nThe table 2 fallacy, first described by [Westreich and Greenland in 2013](../readings/westreich_greenland_2013.pdf), refers to a common misinterpretation in epidemiology and statistics when researchers present multiple adjusted effect estimates in a single table (often \"Table 2\" in academic papers).\n\nThe fallacy occurs when researchers interpret all coefficients in a multiple regression model as total effects, when in fact some are direct effects conditional on the other variables in the model. This can lead to incorrect causal interpretations, particularly when some variables are mediators (lying on the causal pathway between exposure and outcome).\n\nFor example, imagine studying how education affects income, with job type as a mediator:\n\n-   Education → Job Type → Income\n-   Education also directly affects Income\n\nIf you include both education and job type in the same regression model, the coefficient for education represents only its direct effect on income (not mediated through job type), not its total effect. However, researchers often mistakenly interpret it as the total effect.\n\nThis fallacy becomes particularly problematic when: 1. The research question involves understanding total causal effects 2. There are multiple pathways between variables 3. Some variables act as both confounders and mediators\n\nTo avoid this fallacy, researchers should: - Clearly specify which effects (total vs direct) they're interested in - Use appropriate methods like path analysis or mediation analysis when studying causal relationships - Be precise in their interpretation of regression coefficients - Consider creating separate models for different research questions\n\n::: notes\nAs you know, the covariates in a statistical analysis can have a variety of different roles from a causal inference perspective: they can be mediators, confounders, proxy confounders, or competing exposures. If a suitable set of covariates can be identified that removes confounding, we may proceed to estimate our causal effect using a multivariable regression model. In linear regression models, there are only two types of variables: the dependent variable (DV) and independent variables (IVs, or predictors). No further distinction is made between the IVs – specifically, the exposure is by no means a \"special\" IV and is treated just like any other IV. Thus, as you can see, there is a conceptual mismatch between causal theory (DAG) that leads us to formulate a multivariable regression model (that highlights the exposure-outcome relationship and associated statistical adjustment for confounding) and the regression model itself. This conceptual mismatch can easily lead to misinterpretation of the results from a multivariable regression model.\n\nOne particularly widespread misconception is known as mutual adjustment, recently called the Table 2 fallacy since the first table in most epidemiological articles usually describes the study data, and the second table reports the results of a multivariable regression model where the erroneous efforts to illustrate mutual adjustment often appear. To illustrate the fallacy, let us assume that we estimate the effect of X on Y. We know (e.g. from a DAG) that there is only one confounder, Z, so we run the regression Y\\~X+Z. If our background knowledge and the statistical assumptions of the regression (e.g. normality) hold, then the coefficient of X estimates the causal effect of X on Y. The ‘Table 2 fallacy’ is the belief that we can also interpret the coefficient of Z as the effect of Z on Y; indeed, in larger models, the fallacy is the belief that all coefficients have a similar interpretation with respect to Y.\n:::\n\n------------------------------------------------------------------------\n\n### exercise\n\nVisit [https://dagitty.net/learn/graphs/table2-fallacy.html)](https://dagitty.net/learn/graphs/table2-fallacy.html) and scroll down to the first Test Your Knowledge section. Try this exercise as many times as you need to get the correct answer twice in a row.\n\n------------------------------------------------------------------------\n\n### exercise\n\n::::: columns\n::: {.column width=\"65%\"}\n![](images/3-2_table-2.png)\n\n:::\n\n::: {.column width=\"35%\"}\n-   Draw out the DAG model for this research question using [dagitty.net](https://dagitty.net/). (You can model \"personality\" instead of C, N, and their interaction.)\n\n-   Assuming there are no unobserved confounds, which of these coefficients are total effects and which are direct effects?\n\n-   If personality is the primary exposure variable, are there any covariates in here that should not be included?\n\n-   Are there any unobserved confounds?\n:::\n:::::\n\n\n\n",
    "supporting": [
      "lecture03-2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}