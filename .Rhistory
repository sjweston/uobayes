family = bernoulli,
bf( A ~ 0 + d*D,
d ~ 0 + G,
nl = TRUE),
prior = c( prior( normal(0, 1), class = b, nlpar = d)),
iter = 5000, warmup = 1000, chains = 4,
seed = 3
)
posterior_summary(m2)
d <- read_csv("https://raw.githubusercontent.com/sjweston/uobayes/refs/heads/main/files/data/external_data/williams.csv")
d
rethinking::precis(d)
psych::describe(d)
distinct(dat, record_id) %>% count()
distinct(d, record_id) %>% count()
#| code-fold: true
d %>%
count(record_id) %>%
ggplot(aes(x = n)) +
geom_bar(fill = "#1c5253") +
scale_x_continuous("number of days", limits = c(0, NA))
d %>%
count(record_id) %>%
ggplot(aes(x = n)) +
geom_histogram(fill = "#1c5253") +
scale_x_continuous("number of days", limits = c(0, NA))
d %>%
count(record_id) %>%
ggplot(aes(x = n)) +
geom_histogram(fill = "#1c5253", color = "white") +
scale_x_continuous("number of days", limits = c(0, NA))
# Chunk 1
library(tidyverse)
library(psych)
library(cowplot)
library(patchwork)
library(here)
library(brms)
library(tidybayes)
# Chunk 2
knitr::opts_chunk$set(fig.retina=3, echo=TRUE)
theme_set(theme_cowplot())
default_palettes <- list(
c("#5e8485" , "#0f393a") ,
c("#1c5253" , "#5e8485" , "#0f393a") ,
# palette with 5 colours
c( "#1c5253" , "#e07a5f", "#f2cc8f" , "#81b29a" , "#3d405b" ) ,
# same palette interpolated to 8 colours
c( "#1c5253" , "#e07a5f", "#f2cc8f" , "#81b29a" , "#3d405b" , "#a7a844" , "#69306d" )
)
options(ggplot2.discrete.fill = default_palettes,
ggplot2.discrete.colour = default_palettes)
# Chunk 3
d <- read_csv("https://raw.githubusercontent.com/sjweston/uobayes/refs/heads/main/files/data/external_data/williams.csv")
distinct(d, record_id) %>% count()
d %>%
count(record_id) %>%
summarise(median = median(n),
min = min(n),
max = max(n))
# Chunk 4
#| code-fold: true
d %>%
count(record_id) %>%
ggplot(aes(x = n)) +
geom_histogram(fill = "#1c5253", color = "white") +
scale_x_continuous("number of days", limits = c(0, NA))
rethinking::precis(d) %>% round(2)
scale_x_continuous("number of days", limits = c(0, NA)) d
d
rethinking::precis(d) %>% round(2)
rethinking::precis(d, digits = 2)
set.seed(14)
dat %>%
nest(data = c(P_A.std, day, P_A.lag, N_A.lag, steps.pm, steps.pmd, N_A.std, day01)) %>%
slice_sample(n = 16) %>%
unnest(data) %>%
ggplot(aes(x = day, y = N_A.lag)) +
geom_line(color = "grey") +
geom_point(color = "#1c5253", size = 1/2) +
ylab("negative affect (standardized)") +
facet_wrap(~ record_id)
set.seed(14)
d %>%
nest(data = c(P_A.std, day, P_A.lag, N_A.lag, steps.pm, steps.pmd, N_A.std, day01)) %>%
slice_sample(n = 16) %>%
unnest(data) %>%
ggplot(aes(x = day, y = N_A.lag)) +
geom_line(color = "grey") +
geom_point(color = "#1c5253", size = 1/2) +
ylab("negative affect (standardized)") +
facet_wrap(~ record_id)
d %>%
nest(data = c(P_A.std, day, P_A.lag, N_A.lag, steps.pm, steps.pmd, N_A.std, day01))
# scaled time variable
d <- d %>% mutate(day01 = (day - 2) / max((day - 2)))
distinct(d, record_id) %>% count()
d %>%
count(record_id) %>%
summarise(median = median(n),
min = min(n),
max = max(n))
d %>%
nest(data = c(P_A.std, day, P_A.lag, N_A.lag, steps.pm, steps.pmd, N_A.std, day01)) %>%
slice_sample(n = 16) %>%
unnest(data) %>%
ggplot(aes(x = day, y = N_A.lag)) +
geom_line(color = "grey") +
geom_point(color = "#1c5253", size = 1/2) +
ylab("negative affect (standardized)") +
facet_wrap(~ record_id)
# Chunk 1
library(tidyverse)
library(psych)
library(cowplot)
library(patchwork)
library(here)
library(brms)
library(tidybayes)
# Chunk 2
knitr::opts_chunk$set(fig.retina=3, echo=TRUE)
theme_set(theme_cowplot())
default_palettes <- list(
c("#5e8485" , "#0f393a") ,
c("#1c5253" , "#5e8485" , "#0f393a") ,
# palette with 5 colours
c( "#1c5253" , "#e07a5f", "#f2cc8f" , "#81b29a" , "#3d405b" ) ,
# same palette interpolated to 8 colours
c( "#1c5253" , "#e07a5f", "#f2cc8f" , "#81b29a" , "#3d405b" , "#a7a844" , "#69306d" )
)
options(ggplot2.discrete.fill = default_palettes,
ggplot2.discrete.colour = default_palettes)
# Chunk 3
d <- read_csv("https://raw.githubusercontent.com/sjweston/uobayes/refs/heads/main/files/data/external_data/williams.csv")
# scaled time variable
d <- d %>% mutate(day01 = (day - 2) / max((day - 2)))
distinct(d, record_id) %>% count()
d %>%
count(record_id) %>%
summarise(median = median(n),
min = min(n),
max = max(n))
# Chunk 4
#| code-fold: true
d %>%
count(record_id) %>%
ggplot(aes(x = n)) +
geom_histogram(fill = "#1c5253", color = "white") +
scale_x_continuous("number of days", limits = c(0, NA))
# Chunk 5
rethinking::precis(d)
# Chunk 1
library(tidyverse)
library(psych)
library(cowplot)
library(patchwork)
library(here)
library(brms)
library(tidybayes)
# Chunk 2
knitr::opts_chunk$set(fig.retina=3, echo=TRUE)
theme_set(theme_cowplot())
default_palettes <- list(
c("#5e8485" , "#0f393a") ,
c("#1c5253" , "#5e8485" , "#0f393a") ,
# palette with 5 colours
c( "#1c5253" , "#e07a5f", "#f2cc8f" , "#81b29a" , "#3d405b" ) ,
# same palette interpolated to 8 colours
c( "#1c5253" , "#e07a5f", "#f2cc8f" , "#81b29a" , "#3d405b" , "#a7a844" , "#69306d" )
)
options(ggplot2.discrete.fill = default_palettes,
ggplot2.discrete.colour = default_palettes)
# Chunk 3
d <- read_csv("https://raw.githubusercontent.com/sjweston/uobayes/refs/heads/main/files/data/external_data/williams.csv")
# scaled time variable
d <- d %>% mutate(day01 = (day - 2) / max((day - 2)))
distinct(d, record_id) %>% count()
d %>%
count(record_id) %>%
summarise(median = median(n),
min = min(n),
max = max(n))
# Chunk 4
#| code-fold: true
d %>%
count(record_id) %>%
ggplot(aes(x = n)) +
geom_histogram(fill = "#1c5253", color = "white") +
scale_x_continuous("number of days", limits = c(0, NA))
# Chunk 5
rethinking::precis(d)
set.seed(14)
dat %>%
nest(data = c(P_A.std, day, P_A.lag, N_A.lag, steps.pm, steps.pmd, N_A.std, day01)) %>%
slice_sample(n = 16) %>%
unnest(data) %>%
ggplot(aes(x = day, y = N_A.lag)) +
geom_line(color = "#80A0C7") +
geom_point(color = "#FCF9F0", size = 1/2) +
ylab("negative affect (standardized)") +
facet_wrap(~ record_id)
set.seed(14)
d %>%
nest(data = c(P_A.std, day, P_A.lag, N_A.lag, steps.pm, steps.pmd, N_A.std, day01)) %>%
slice_sample(n = 16) %>%
unnest(data) %>%
ggplot(aes(x = day, y = N_A.lag)) +
geom_line(color = "#80A0C7") +
geom_point(color = "#FCF9F0", size = 1/2) +
ylab("negative affect (standardized)") +
facet_wrap(~ record_id)
d %>%
nest(-record_id)
d %>%
nest(data=-record_id)
d %>%
nest(data=-record_id) %>%
slice_sample(n = 16)
d %>%
nest(data=-record_id) %>%
slice_sample(n = 16) %>%
unnest(data)
d %>%
nest(data=-record_id) %>%
slice_sample(n = 16) %>%
unnest(data) %>%
ggplot(aes(x = day, y = N_A.lag))
d %>%
nest(data=-record_id) %>%
slice_sample(n = 16) %>%
unnest(data) %>%
ggplot(aes(x = day, y = N_A.lag)) +
geom_line(color = "#80A0C7") +
geom_point(color = "#FCF9F0", size = 1/2) +
ylab("negative affect (standardized)") +
facet_wrap(~ record_id)
d %>%
nest(data=-record_id) %>%
slice_sample(n = 16) %>%
unnest(data) %>%
ggplot(aes(x = day, y = N_A.lag)) +
geom_line(color = "grey") +
geom_point(color = "#1c5253", size = 1/2) +
ylab("negative affect (standardized)") +
facet_wrap(~ record_id)
m1 <-
brm(data = d,
family = gaussian,
N_A.std ~ 1 + day01 + (1 + day01 | record_id),
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 1), class = b),
prior(exponential(1), class = sd),
prior(exponential(1), class = sigma),
prior(lkj(2), class = cor)),
iter = 3000, warmup = 1000, chains = 4, cores = 4,
seed = 14,
file = here("file/models/m81.1"))
m1 <-
brm(data = d,
family = gaussian,
N_A.std ~ 1 + day01 + (1 + day01 | record_id),
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 1), class = b),
prior(exponential(1), class = sd),
prior(exponential(1), class = sigma),
prior(lkj(2), class = cor)),
iter = 3000, warmup = 1000, chains = 4, cores = 4,
seed = 14,
file = here("files/models/m81.1"))
m2 <-
brm(data = d,
family = gaussian,
bf(N_A.std ~ 1 + day01 + (1 + day01 |i| record_id),
sigma ~ 1 + (1 |i| record_id)),
prior = c(prior(normal(0, 0.2), class = Intercept),
prior(normal(0, 1), class = b),
prior(exponential(1), class = sd),
prior(normal(0,1), class = Intercept, dpar=sigma),
prior(exponential(1), class = sd, dpar=sigma),
prior(lkj(2), class = cor)),
iter = 3000, warmup = 1000, chains = 4, cores = 4,
seed = 14,
file = here("files/models/m81.2"))
# Chunk 1
library(tidyverse)
library(psych)
library(cowplot)
library(patchwork)
library(here)
library(brms)
library(tidybayes)
# Chunk 2
knitr::opts_chunk$set(fig.retina=3, echo=TRUE)
theme_set(theme_cowplot())
default_palettes <- list(
c("#5e8485" , "#0f393a") ,
c("#1c5253" , "#5e8485" , "#0f393a") ,
# palette with 5 colours
c( "#1c5253" , "#e07a5f", "#f2cc8f" , "#81b29a" , "#3d405b" ) ,
# same palette interpolated to 8 colours
c( "#1c5253" , "#e07a5f", "#f2cc8f" , "#81b29a" , "#3d405b" , "#a7a844" , "#69306d" )
)
options(ggplot2.discrete.fill = default_palettes,
ggplot2.discrete.colour = default_palettes)
# Chunk 3: entropy-viz
#| code-fold: true
#|
# Create example data
set.seed(123)
# Low entropy data (concentrated around a single value)
low_entropy <- data.frame(
value = sample(x = c(1:6), 10000, replace = T, prob = c(.3, .25, .2, .1, .05, 0)),
type = "Low Entropy"
)
# High entropy data (more spread out, more uniform)
high_entropy <- data.frame(
value = sample(x = c(1:6), 10000, replace = T),
type = "High Entropy"
)
# Combine the data
entropy_data <- rbind(low_entropy, high_entropy)
# Create the plots
ggplot(entropy_data, aes(x = value)) +
geom_histogram(fill = "#1c5253", alpha = 0.5, binwidth = 1, color = "white") +
facet_wrap(~type) +
labs(title = "Comparing High and Low Entropy Distributions",
x = "Value",
y = "Density") +
theme_cowplot() +
theme(strip.background = element_rect(fill = "#1c5253"),
strip.text = element_text(color = "white", size = 12))
# Chunk 4: binomial-viz
#| code-fold: true
# Create data for different rate parameters
x <- seq(0, 100, by=1)
N <- c(1, 5, 100)
p = c(.25, .40, .70)
binom_data <- expand.grid(x = x, N=N, p=p) %>%
filter(x <= N) %>%
mutate(density = dbinom(x, prob = p, size=N),
p=str_c("p = ", p),
N = factor(N, levels=c(1, 5, 100), labels=c("001", "005", "100")),
N=str_c("N = ",N))
ggplot(binom_data, aes(x = x, y = density, fill = p)) +
#geom_line(linewidth = 1) +
geom_bar(stat="identity") +
labs(title = "Binomial Distribution with Different Parameters",
x = "x",
y = "Density",
color = "p") +
theme_cowplot() +
facet_wrap(p~N, scales="free") +
guides(color=F, fill=F)
# Chunk 5: exponential-viz
#| code-fold: true
# Create data for different rate parameters
x <- seq(0, 5, length.out = 1000)
rates <- c(0.5, 1, 2)
exp_data <- expand.grid(x = x, rate = rates) %>%
mutate(density = dexp(x, rate),
rate = factor(rate, labels = paste("λ =", rates)))
ggplot(exp_data, aes(x = x, y = density, color = rate)) +
geom_line(size = 1) +
labs(title = "Exponential Distribution with Different Rate Parameters",
x = "x",
y = "Density",
color = "Rate") +
theme_cowplot() +
scale_color_manual(values = c("#1c5253", "#5e8485", "#0f393a"))
# Chunk 6: gamma-viz
#| code-fold: true
# Create data for different shape parameters
x <- seq(0, 10, length.out = 1000)
shapes <- list(c(1, 1), c(2, 2), c(5, 1))
names <- c("a=1, b=1", "a=2, b=2", "a=5, b=1")
gamma_data <- map_df(seq_along(shapes), function(i) {
data.frame(
x = x,
density = dgamma(x, shape = shapes[[i]][1], rate = shapes[[i]][2]),
params = names[i]
)
})
ggplot(gamma_data, aes(x = x, y = density, color = params)) +
geom_line(size = 1) +
labs(title = "Gamma Distribution with Different Shape and Rate Parameters",
x = "x",
y = "Density",
color = "Parameters") +
theme_cowplot() +
scale_color_manual(values = c("#1c5253", "#5e8485", "#0f393a"))
# Chunk 7: poisson-viz
#| code-fold: true
# Create data for different lambda parameters
x <- 0:15
lambdas <- c(1, 3, 7)
pois_data <- expand.grid(x = x, lambda = lambdas) %>%
mutate(probability = dpois(x, lambda),
lambda = factor(lambda, labels = paste("λ =", lambdas)))
ggplot(pois_data, aes(x = x, y = probability, fill = lambda)) +
geom_col(position = "dodge", alpha = 0.7) +
labs(title = "Poisson Distribution with Different Rate Parameters",
x = "Count",
y = "Probability",
fill = "Lambda") +
theme_cowplot() +
scale_fill_manual(values = c("#1c5253",  "#e07a5f", "#f2cc8f"))
# Chunk 8
# generative model, basic mediator scenario
set.seed(0319)
N <- 1000 # number of applicants
# even gender distribution
G <- sample( 1:2, size=N, replace=TRUE )
# gender 1 tends to apply to department 1, 2 to 2
D <- rbinom( n=N, size=1, prob=ifelse( G==1 , 0.3 , 0.8 ) ) + 1
# matrix of acceptance rates
accept_rate <- matrix( c(0.5, 0.2, 0.1, 0.3), nrow=2)
# simulate acceptance
A <- rbinom( n=N, size=1, accept_rate[D,G])
dat <- data.frame(D=as.character(D), G=as.character(G), A)
# Chunk 9
m1 = brm(
data = dat,
family = bernoulli,
A  ~ 0 + G,
prior = c( prior( normal(0, 1), class = b)),
iter = 5000, warmup = 1000, chains = 4,
seed = 3,
file = here("files/models/51.1")
)
# Chunk 10
m1
# Chunk 11
m2 = brm(
data = dat,
family = bernoulli,
A  ~ G*D,
prior = c( prior( normal(0, 1), class = Intercept),
prior( normal(0, 1), class = b)),
iter = 5000, warmup = 1000, chains = 4,
seed = 3,
file = here("files/models/51.2")
)
# Chunk 12
m2
# Chunk 13
#| code-fold: true
posterior_summary(m1) %>% round(2)
# Chunk 14
#| code-fold: true
posterior_summary(m2) %>% round(2)
# Chunk 15
new_dat = expand.grid(G = c("1", "2"),
D = c("1", "2"))
m1 %>% add_epred_draws(newdata = new_dat) %>%
head()
m1 %>% add_epred_draws(newdata = new_dat) %>%
median_qi
m2 %>% add_epred_draws(newdata = new_dat) %>%
median_qi
m2 %>% add_epred_draws(newdata = new_dat) %>%
mean_hdi()
dat %>% count(A, D, G)
dat %>% count(A, D, G) %>% with_groups(c(G,D), mutate, total=sum(A))
dat %>% count(A, D, G) %>% with_groups(c(G,D), mutate, total=sum(n))
dat %>% count(A, D, G) %>% with_groups(c(G,D), mutate, total=sum(n)) %>% mutate(prob = n/total) %>% filter(A==1)
m1 %>% add_predicted_draws(newdata = new_dat) %>%
head
m4 <- brm(
data = UCBadmit,
family = binomial,
admit | trials(applications) ~ gender*dept,
prior = c( prior( normal(0, 2), class = Intercept),
prior( normal(0, 2), class = b) ),
iter = 5000, warmup = 1000, chains = 4,
seed = 3,
file = here("files/models/51.4")
)
data(UCBadmit, package = "rethinking")
UCBadmit$gender = UCBadmit$applicant.gender
m3 <- brm(
data = UCBadmit,
family = binomial,
admit | trials(applications) ~ 0 + gender,
prior = c( prior( normal(0, 2), class = b) ),
iter = 5000, warmup = 1000, chains = 4,
seed = 3,
file = here("files/models/51.3")
)
spread_draws(m4, starts_with("b_"))
UCBadmit %>% add_epred_draws(m3) %>%
ungroup() %>%
select(dept, gender, applications, admit, reject, .draw, .epred)
UCBadmit %>% add_epred_draws(m3) %>%
mean_qi
UCBadmit %>% add_epred_draws(m3) %>%
ungroup() %>%
mean_qi(.epred)
UCBadmit %>% add_epred_draws(m3) %>%
ungroup()
UCBadmit %>% add_epred_draws(m3) %>%
ungroup() %>%
group_by(gender) %>%
mean_qi(.epred)
UCBadmit
UCBadmit %>%
distinct(gender, dept, applications)
library(loo)
m3 <- add_criterion(m3, criterion = "loo")
m4 <- add_criterion(m4, criterion = "loo")
loo_compare(m3, m4)
loo_compare(m3, m4) %>% print(simplify=F)
loo_compare(m3, m4) %>% print(simplify=F)
